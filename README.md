# Python automation script for processing and summarising CSV data

## The Problem

"I recieve X number of large CSV files per week and spend hours trying to process them, and extract useful information from them"

This project is designed to solve this precise issue by automating repetitive CSV processing. Accurate and meaningful results can be achieved quickly, avoiding human error, and the many hours it may otherwise take (sometimes to the point of being impractical to undertake). 

## How it Works

The script monitors a directory (``data/raw``) where new CSV files are placed. For the purposes of this project, CSV files are generated by pulling data from an API using a seperate script called ``data_import.py``, and converting the response to CSV using the pandas Python library. However, new CSV files can also be manually placed in ``data/raw``

Data is validated and cleaned by handling missing values and filtering duplicate values. ==TODO==

The validated data is then fed through a summariser script called ``summary.py``, to give a general overview of what is shown in the data. This includes counts for specific categories of items, and key statistics comparing categories.

The summary and cleaned version of the CSV file are exported to ``data/processed``.

Logs and errors ==TODO==
All logs and errors begin with a timestamp. ==logs and error go to a file??==

## Example Output

For an example run, the script uses data from a makeup data API: https://makeup-api.herokuapp.com/
The data import script uses the https://makeup-api.herokuapp.com/api/v1/products.json endpoint.

## How to Run

## Tech Stack

## customisation notes